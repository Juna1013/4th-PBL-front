# 音声認識フロントエンド統合 - 実装完了

## 🎉 新機能

### 1. 音声認識制御ページ
- **URL**: `/speech`
- **機能**: 音声録音→認識→コマンド送信の一連の流れを実装
- **特徴**: 
  - リアルタイム音声録音
  - 音声認識結果の可視化
  - 自動/手動コマンド実行
  - 詳細設定（信頼度閾値調整）

### 2. 新しいReactコンポーネント

#### SpeechRecognition.tsx
- 音声録音UI
- 認識結果表示
- 設定パネル
- エラーハンドリング

#### useSpeechRecognition.ts
- 音声録音フック
- API通信フック
- 権限管理
- ファイル変換ユーティリティ

### 3. APIサービス拡張
- `api.ts` に音声認識用エンドポイント追加
- TypeScript型定義を完備
- エラーハンドリング強化

## 🚀 使用方法

### 開発環境での起動
```bash
# フロントエンド
cd web
npm run dev

# バックエンド（別ターミナル）
cd server
source venv/bin/activate
python -m app.main
```

### 音声認識の使用手順
1. **http://localhost:5173/speech** にアクセス
2. ブラウザのマイク権限を許可
3. 「音声録音開始」をクリック
4. 以下のコマンドを明瞭に発話：
   - **go** (前進)
   - **right** (右折)
   - **left** (左折)
   - **stop** (停止)
5. 「録音停止」→「音声認識実行」
6. 結果確認後、必要に応じてコマンド送信

## 📱 ページ構成

### メインページ (/)
- 音声認識制御への新しいナビゲーションタイル追加
- 4つのメインセクションに再構成

### 音声認識ページ (/speech)
- **左側**: 音声認識メインパネル
  - 録音コントロール
  - 設定パネル（詳細表示切替可能）
  - 認識結果表示
  - 使用手順ガイド
- **右側**: サイドバー
  - 現在のコマンド表示
  - 最後に送信したコマンド
  - システム状態
  - クイックナビゲーション

## 🔧 技術仕様

### フロントエンド技術スタック
- **Next.js 15** - Reactフレームワーク
- **TypeScript** - 型安全性
- **TailwindCSS** - スタイリング
- **React Query** - APIキャッシュと状態管理
- **Axios** - HTTP通信
- **Lucide React** - アイコン

### ブラウザAPI
- **MediaDevices API** - マイクアクセス
- **MediaRecorder API** - 音声録音
- **Permissions API** - 権限チェック

### 音声形式サポート
- **録音形式**: WebM (Opus codec)
- **サンプルレート**: 16kHz（音声認識最適化）
- **ファイル形式**: WebMからFileオブジェクトに変換

## ⚙️ 設定オプション

### 音声認識設定
- **信頼度閾値**: 0.5-0.95（デフォルト: 0.7）
- **自動実行**: 録音完了時に自動で認識実行
- **自動コマンド送信**: 信頼度が閾値を超えた場合に自動送信

### 録音設定
- **エコーキャンセレーション**: 有効
- **ノイズ抑制**: 有効
- **最適録音時間**: 1-3秒
- **最大録音時間**: 10秒

## 🔍 デバッグとトラブルシューティング

### よくある問題

1. **マイク権限エラー**
   ```
   解決策: ブラウザ設定でマイク権限を許可
   Chrome: 設定 > プライバシーとセキュリティ > サイトの設定 > マイク
   ```

2. **音声認識エラー**
   ```
   解決策: 
   - バックエンドサーバーが起動している確認
   - ネットワーク接続確認
   - 開発者ツールでAPIエラーログ確認
   ```

3. **録音品質問題**
   ```
   改善策:
   - 静かな環境で録音
   - マイクに近づく
   - 明瞭に発話
   - 録音時間を1-3秒に調整
   ```

### デバッグコマンド
```bash
# フロントエンドログ確認
# ブラウザ開発者ツール > Console

# バックエンドログ確認
tail -f server/app.log

# APIテスト
curl -X GET http://localhost:8000/api/speech/commands
```

## 🌐 本番環境デプロイ

### 環境変数設定
```bash
# .env.production
NEXT_PUBLIC_API_URL=https://your-backend-api.onrender.com/api
```

### Vercel デプロイ
```bash
npm run build
# または
vercel deploy --prod
```

### 注意事項
- **HTTPS必須**: 本番環境ではHTTPS接続が必要（マイクアクセスのため）
- **CORS設定**: バックエンドでフロントエンドドメインを許可
- **タイムアウト設定**: 音声処理のため長めのタイムアウト（30秒）

## 📊 パフォーマンス最適化

### 実装済み最適化
- **React Query** によるAPIレスポンスキャッシュ
- **lazy loading** での大きなコンポーネント分割
- **debounce** による不要なAPI呼び出し抑制
- **メモリ管理** Blob URLの適切な開放

### 推奨設定
- **録音品質**: 16kHz, モノラル, Opus
- **ファイルサイズ制限**: 10MB
- **キャッシュ**: APIレスポンス5分間
- **タイムアウト**: 音声認識30秒、その他10秒

## 🔒 セキュリティ考慮事項

### 実装済み対策
- **ファイルサイズ制限**: 最大10MB
- **MIME-type検証**: audio/webm のみ許可
- **タイムアウト保護**: 長時間接続防止
- **エラーハンドリング**: 機密情報の漏洩防止

### 推奨追加対策
- **レート制限**: API呼び出し頻度制限
- **認証機能**: 将来的なユーザー管理
- **監査ログ**: セキュリティイベント記録

## 🎯 今後の改善点

### 短期的改善
- [ ] 音声認識精度の向上
- [ ] より多くの音声形式サポート
- [ ] オフライン機能対応
- [ ] PWA対応

### 長期的改善  
- [ ] リアルタイム音声認識
- [ ] 多言語対応
- [ ] カスタムコマンド追加機能
- [ ] 音声合成フィードバック

---

✅ **音声認識機能のフロントエンド統合が完了しました！**

ユーザーは直感的なUIで音声コマンドを録音し、リアルタイムでライントレースカーを制御できるようになりました。